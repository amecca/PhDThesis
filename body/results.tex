\chapter{Results}

The analysis strategy is to search for excess events over the estimated background yield.
Two different selections for the photon and several kinematic distributions are explored,
and the expected significance of the ecesses compared to determine the best strategy.

\todo{pp to 4l+gamma inclusive measurement.}
Additionally, the total cross section of the processes
$p p \to 4 \Pl \PGg$ and $p p \to 3 \Pl \PGn \PGg$ and $p p \to 3 \Pl \PGn \PGg$ are measured,
including FSR contributions with large angle.

\section{Yields and kinematic distributions}
\input{results/yields.tex}

\section{Statistical analysis}
\label{sec:statistical_analysis}
The likelihood function is defined as the Probability Density Function for a set of parameters of a model, given a certain set of experimental observables (data).
The model adopted for this analysis defines a signal strength modifier $\mu$, that multiplies the cross section of the $ZZ\gamma$ signal and leaves all the other processes unchanged.
Each independent source of systematic uncertainty described in Section \ref{sec:systematics} is assigned a nuisance parameter $\theta_i$, and the full set is denoted $\vec\theta$.
They are of no direct interest for this analysis, but must be considered in the fitting procedure to extract correct results.
They enter the model through their PDF $p_i(\tilde{\theta_i}|\theta_i)$, which is the probability of measuring a certain value of the parameter given that the true value is $\theta_i$.
Furthermore, the expected yields of background, $b$, and signal, $s$, depend on the value of the nuisance parameters.

The global likelihood function is thus defined as:
\begin{equation}
  \label{eq:likelihood_full}
  \Likelihood(data\, |\, \mu, \vec\theta\,) = \prod_c \Likelihood_c(data\, |\, \mu \cdot s(\vec\theta\,) + b(\vec\theta\,)) \cdot \prod_i p_i(\tilde{\theta_i}\, |\, \theta_i)
\end{equation}
where c runs over all the channels, which are the four data-taking periods (2016preVFP, 2016postVFP, 2017, 2018).
The extraction of the signal strength proceeds through the maximisation of the complete likelihood function by varying the parameter of interest $\mu$ and the nuisances.
The $\Likelihood_c$ functions are the PDF of the binned distributions in each channel, and are given by the product of Poisson probabilities for every bin $j$ to observe $n_j$ events:
\begin{equation}
  \label{eq:likelihood_bin}
  \Likelihood_c(data\, |\, \mu \cdot s(\vec\theta\,) + b(\vec\theta\,)) = \prod_j \frac{\mu \cdot s_j(\vec\theta\,) + b_j(\vec\theta\,)}{n_j!} e^{-(\mu \cdot s_j(\vec\theta\,) + b_j(\vec\theta\,))}
\end{equation}

\subsection{Treatment of nuisance parameters}
Systematics uncertainties can be categorised into two main classes: the ones that affect only the event yield, and those that have an impact also on the shape of the predicted distributions.
Most of the uncertainties of the first class are parametrised with a log-normal distribution:
\begin{equation}
  \label{eq:lnNdef}
  \Probability(\tilde{\theta}\,|\,\theta) = \frac{1}{\sqrt{2 \pi} \text{ln} k} \cdot \frac{1}{\tilde{\theta}} \cdot \text{exp} \left( -\frac{(\text{ln}(\tilde{\theta}/\theta_m))^2}{2 \text{ln}^2 k} \right)
\end{equation}
which is the distribution of a random variable whose logarithm is normally distributed, with mean $\mu$ = $\text{ln}(\theta_m)$ and standard deviation $\sigma$ = $\text{ln}(k)$.
%% where the parameters $theta_s$ and $k$ can be defined in terms of the mean and standard deviation of a normally distributed variable: $\theta_m = e^{\mu}$ and $k = e^{\sigma}$.
The log-normal is used instead of a Gaussian because it enforces the positive-definite normalisation for the nuisance modelled, which is usually multiplying an event yield and thus cannot be negative.

The remaining systematics in the first class are those that represent a background coming from a statistically limited control region, such as the fake leptons and photons.
These are dominated by the statistically uncertainty in the control region and are modelled with a Gamma distribution:
\begin{equation}
  \label{eq:gammadef}
  \Probability(\theta\,|\,N\alpha) = \frac{1}{\Gamma(N) \alpha^N} \theta^{N-1} e^{-\theta/\alpha}
\end{equation}
where $N$ is the number of events in the control region, $\theta$ is the average transfer factor and $\Gamma(x)$ is the Gamma function.

The shape uncertainties of the second class are accounted for by interpolating the event fraction for each bin of three histograms: the one obtained for the central value, and the two obtained by shifting the nuisance parameter up and down by one standard deviation.

\subsection{Quantifying an excess}
To quantify the statistical significance of an excess of events over the background-only hypothesis, the following test statistic is used:
\begin{equation}
  \label{eq:test_statistic}
  t_0 = -2\text{ln} \frac {\Likelihood(data\,|\,0,\widehat{\vec{\theta_0}}\,)} {\Likelihood(data\,|\,\hat\mu,\widehat{\vec\theta}\,)}\,,\quad \text{with}\, \hat\mu \ge 0
\end{equation}

The numerator is evaluated under the background-only hypothesis ($\mu$ = 0), and $\widehat{\vec{\theta_0}}$ is the set of values of nuisance parameters that maximises it under this null hypothesis.
The denominator is evaluated under the alternative signal + background hypothesis, and the values $\hat{\mu}$ and $\hat{\vec{\theta}}$ are those that maximise the likelihood in this hypothesis.
This quantity is positive for a signal-like excess ($\mu$ > 0) and becomes 0 in the absence of an excess ($\mu$ = 0).

The significativity of an excess is expressed in terms of the local \textit{p-value}, which is the probability to obtain a value of the test statistic $t_0$ greater than or equal to the one observed in experimental data, under the background-only hypothesis:
\begin{equation}
  \label{eq:pvalue}
  p_0 = \Probability(t_0 \ge t_0^{obs}\, |\, \mu = 0)
\end{equation}
That is, $p_0$ is the probability that a local statistical fluctuation of the background resembles the signal at least as much as the observed data do.

The p-value is usually expressed as a \textit{significance} $Z$ using the Gaussian one-sided integral:
\begin{equation}
  \label{eq:significance}
  p_0 = \int_Z^\infty \frac{1}{\sqrt{2\pi}}e^{-x^2/2}dx
\end{equation}

The conventional values of $Z$ = 3$\sigma$ and $Z$ = 5$\sigma$, corresponding to p-values of $1.3 \cdot 10^{-3}$ and $2.8 \cdot 10^{-7}$, are used to claim evidence for and the discovery of a new phenomenon respectively.

\section{Comparison of strategies}
As mentioned in Sections \ref{sec:evt_photon_selection} and \ref{sec:FSR_cut},
different approaches are used to select the photon
and results are reported both including and excluding the FSR contribution.

Additionally, several event variables are tested for the final fit to the signal strenght.

The first is the invariant mass of the $\PZ\PZ\PGg$ system.
It is expected to be higher for triboson events where the photon comes from the hard scattering than for FSR.
Additionally, it is expected to be sensitive to Beyond Standard Model (BSM) contributions, expecially in the high-energy tail.

The second variable is the transverse momentum of the photon.
As the $\PZ\PZ\PGg$ mass, it is presumed to be sensitive to BSM physics in the high-momentum tail.

The third option considered is the MVA-based ID working point passed by the photon.
Three bins are defined:
\begin{itemize}
\item \makebox[7em][l]{\bf wp80} The photon passes the \texttt{wp80} working point;
\item \makebox[7em][l]{\bf $\mathrm{wp90} \land \mathrm{!wp80}$} The photon passes \texttt{wp90}, but fails \texttt{wp80};
\item \makebox[7em][l]{\bf None} The photon fails \texttt{wp90};
\end{itemize}
The yield of the simulation is scaled in each bin according to the appropriate scale factors (see Section \ref{sec:photonID}).

This section reports the results for all of the combination of the aforementioned choices of the analysis strategy.

\subsection{Results including FSR}

\subsubsection{Cut-based ID}
\providecommand{\impactswidthscale}{0.6}
The \nonprompt photon contribution is estimated using the data-driven approach.
The variable considered is $m_{\PZ\PZ\PGg}$.
The impacts of the systematic uncertainties on the expected results is shown in Figure \ref{fig:inclusive_cutID_phoCR_mZZGloose}.

\begin{figure}
  \centering
  \includegraphics[height=0.33\textheight]{Figures/dataMC/Run2/phoCR/SR4P/SYS_mZZGloose_central_pow.pdf}
  \hfill
  \includegraphics[height=0.33\textheight]{Run2_SR4P_phoCR_lepCR_mZZGloose_impacts.pdf}
  \caption{Distribution and impacts of the systematic uncertainties on the signal strength fit
    on the mass of the $\PZ\PZ\PGg$ system,
    using the Loose working point of the photon cut-based ID.
    The data-driven estimate for \nonprompt photons is used.
    The FSR cut is not applied.
  }
  \label{fig:inclusive_cutID_phoCR_mZZGloose}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[height=0.33\textheight]{Figures/dataMC/Run2/lepCR/SR4P/lead_loose_pt_pow.pdf}
  \hfill
  \includegraphics[height=0.33\textheight]{Run2_SR4P_phoMC_lepCR_loosept_impacts.pdf}
  \caption{Distribution and impacts of the systematic uncertainties on the signal strength fit
    on the transverse momentum of the photon,
    using the Loose working point of the photon cut-based ID.
    \Nonprompt photons are estimated from simulation.
    The FSR cut is not applied.
  }
  \label{fig:inclusive_cutID_phoMC_loosept}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[height=0.33\textheight]{Figures/dataMC/Run2/lepCR/SR4P/SYS_wp90pt_central_pow.pdf}
  \hfill
  \includegraphics[height=0.33\textheight]{Run2_SR4P_phoMC_lepCR_mZZGwp90_impacts.pdf}
  \caption{Distribution and impacts of the systematic uncertainties on the signal strength fit
    on the mass of the $\PZ\PZ\PGg$ system,
    using the \texttt{wp90} working point of the photon MVA ID.
    \Nonprompt photons are estimated from simulation.
    The FSR cut is not applied.
  }
  \label{fig:inclusive_mvaID_phoMC_mZZGwp90}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[height=0.33\textheight]{Figures/dataMC/Run2/lepCR/SR4P/SYS_wp80pt_central_pow.pdf}
  \hfill
  \includegraphics[height=0.33\textheight]{Run2_SR4P_phoMC_lepCR_mZZGwp80_impacts.pdf}
  \caption{Distribution and impacts of the systematic uncertainties on the signal strength fit
    on the mass of the $\PZ\PZ\PGg$ system,
    using the \texttt{wp80} working point of the photon MVA ID.
    \Nonprompt photons are estimated from simulation.
    The FSR cut is not applied.
  }
  \label{fig:inclusive_mvaID_phoMC_mZZGwp80}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[height=0.33\textheight]{Figures/dataMC/Run2/lepCR/SR4P/SYS_MVAcut_central_pow.pdf}
  \hfill
  \includegraphics[height=0.33\textheight]{Run2_SR4P_phoMC_lepCR_MVAcut_impacts.pdf}
  \caption{Distribution and impacts of the systematic uncertainties on the signal strength fit
    on the yield in the various bins of the photon MVA ID.
    \Nonprompt photons are estimated from simulation.
    The FSR cut is not applied.
  }
  \label{fig:inclusive_kin_phoMC_MVAcut}
\end{figure}

\begin{table}
  \caption{Summary of the results on the signal significance with the various strategies.}
  \label{tab:summary_significances_inclusive}
  \begin{tabular}{lllll}
    \toprule
    FSR cut                      & Photon ID                          & \nonprompt \PGg & Variable         & Significance\\
    \midrule
    \multirow{5}{*}{Not applied} & \multirow{2}{*}{Cut-based (Loose)} & data-driven     & $m_{\PZ\PZ\PGg}$ & 3.06 $\sigma$\\
                                 &                                    & simulation      & $\pt^\PGg$       & 3.20 $\sigma$\\
                                 & MVA (\texttt{wp90})                & simulation      & $m_{\PZ\PZ\PGg}$ & 3.34 $\sigma$\\
                                 & MVA (\texttt{wp80})                & simulation      & $m_{\PZ\PZ\PGg}$ & 3.26 $\sigma$\\
                                 & Kinematic                          & simulation      & MVA score        & 3.32 $\sigma$\\
    \hline
    \multirow{5}{*}{Applied}     & \multirow{2}{*}{Cut-based (Loose)} & data-driven     & $m_{\PZ\PZ\PGg}$ & X $\sigma$  \\
                                 &                                    & simulation      & $\pt^\PGg$       & X $\sigma$  \\
                                 & MVA (\texttt{wp90})                & simulation      & $m_{\PZ\PZ\PGg}$ & X $\sigma$  \\
                                 & MVA (\texttt{wp80})                & simulation      & $m_{\PZ\PZ\PGg}$ & X $\sigma$  \\
                                 & Kinematic                          & simulation      & MVA score        & X $\sigma$  \\
    \bottomrule
  \end{tabular}
\end{table}
